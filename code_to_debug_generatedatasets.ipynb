{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from tracker import Tracker\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# vim: expandtab:ts=4:sw=4\n",
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(object):\n",
    "\n",
    "    def __init__(self, checkpoint_filename, input_name=\"images\",\n",
    "                 output_name=\"features\"):\n",
    "        self.session = tf.compat.v1.Session()\n",
    "        with tf.io.gfile.GFile(checkpoint_filename, \"rb\") as file_handle:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(file_handle.read())\n",
    "        tf.import_graph_def(graph_def, name=\"net\")\n",
    "\n",
    "        # Debug: Print out all tensor names to verify\n",
    "        print(\"Available tensors:\")\n",
    "        print([n.name for n in graph_def.node])\n",
    "\n",
    "        self.input_var = tf.compat.v1.get_default_graph().get_tensor_by_name(\n",
    "            \"%s:0\" %input_name)\n",
    "        self.output_var = tf.compat.v1.get_default_graph().get_tensor_by_name(\n",
    "            \"%s:-1\" % output_name)\n",
    "\n",
    "        assert len(self.output_var.get_shape()) == 2\n",
    "        assert len(self.input_var.get_shape()) == 4\n",
    "        self.feature_dim = self.output_var.get_shape().as_list()[-1]\n",
    "        self.image_shape = self.input_var.get_shape().as_list()[1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, data_x, batch_size=32):\n",
    "        out = np.zeros((len(data_x), self.feature_dim), np.float32)\n",
    "        _run_in_batches(\n",
    "            lambda x: self.session.run(self.output_var, feed_dict=x),\n",
    "            {self.input_var: data_x}, out, batch_size)\n",
    "        return out\n",
    "\n",
    "\n",
    "def create_box_encoder(model_filename, input_name=\"images\",\n",
    "                       output_name=\"features\", batch_size=32):\n",
    "    image_encoder = ImageEncoder(model_filename, input_name, output_name)\n",
    "    image_shape = image_encoder.image_shape\n",
    "\n",
    "    def encoder(image, boxes):\n",
    "        image_patches = []\n",
    "        for box in boxes:\n",
    "            patch = extract_image_patch(image, box, image_shape[:2])\n",
    "            if patch is None:\n",
    "                print(\"WARNING: Failed to extract image patch: %s.\" % str(box))\n",
    "                patch = np.random.uniform(\n",
    "                    0., 255., image_shape).astype(np.uint8)\n",
    "            image_patches.append(patch)\n",
    "        image_patches = np.asarray(image_patches)\n",
    "        return image_encoder(image_patches, batch_size)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tensors:\n",
      "['images', 'Cast', 'map/Shape', 'map/strided_slice/stack', 'map/strided_slice/stack_1', 'map/strided_slice/stack_2', 'map/strided_slice', 'map/TensorArray', 'map/TensorArrayUnstack/Shape', 'map/TensorArrayUnstack/strided_slice/stack', 'map/TensorArrayUnstack/strided_slice/stack_1', 'map/TensorArrayUnstack/strided_slice/stack_2', 'map/TensorArrayUnstack/strided_slice', 'map/TensorArrayUnstack/range/start', 'map/TensorArrayUnstack/range/delta', 'map/TensorArrayUnstack/range', 'map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3', 'map/Const', 'map/TensorArray_1', 'map/while/Enter', 'map/while/Enter_1', 'map/while/Merge', 'map/while/Merge_1', 'map/while/Less', 'map/while/Less/Enter', 'map/while/LoopCond', 'map/while/Switch', 'map/while/Switch_1', 'map/while/Identity', 'map/while/Identity_1', 'map/while/TensorArrayReadV3', 'map/while/TensorArrayReadV3/Enter', 'map/while/TensorArrayReadV3/Enter_1', 'map/while/strided_slice/stack', 'map/while/strided_slice/stack_1', 'map/while/strided_slice/stack_2', 'map/while/strided_slice', 'map/while/TensorArrayWrite/TensorArrayWriteV3', 'map/while/TensorArrayWrite/TensorArrayWriteV3/Enter', 'map/while/add/y', 'map/while/add', 'map/while/NextIteration', 'map/while/NextIteration_1', 'map/while/Exit_1', 'map/TensorArrayStack/TensorArraySizeV3', 'map/TensorArrayStack/range/start', 'map/TensorArrayStack/range/delta', 'map/TensorArrayStack/range', 'map/TensorArrayStack/TensorArrayGatherV3', 'conv1_1/weights', 'conv1_1/weights/read', 'conv1_1/Conv2D', 'conv1_1/conv1_1/bn/Const', 'conv1_1/conv1_1/bn/beta', 'conv1_1/conv1_1/bn/beta/read', 'conv1_1/conv1_1/bn/moving_mean', 'conv1_1/conv1_1/bn/moving_mean/read', 'conv1_1/conv1_1/bn/moving_variance', 'conv1_1/conv1_1/bn/moving_variance/read', 'conv1_1/conv1_1/bn/FusedBatchNorm', 'conv1_1/Elu', 'conv1_2/weights', 'conv1_2/weights/read', 'conv1_2/Conv2D', 'conv1_2/conv1_2/bn/Const', 'conv1_2/conv1_2/bn/beta', 'conv1_2/conv1_2/bn/beta/read', 'conv1_2/conv1_2/bn/moving_mean', 'conv1_2/conv1_2/bn/moving_mean/read', 'conv1_2/conv1_2/bn/moving_variance', 'conv1_2/conv1_2/bn/moving_variance/read', 'conv1_2/conv1_2/bn/FusedBatchNorm', 'conv1_2/Elu', 'pool1/MaxPool', 'conv2_1/1/weights', 'conv2_1/1/weights/read', 'conv2_1/1/Conv2D', 'conv2_1/1/conv2_1/1/bn/Const', 'conv2_1/1/conv2_1/1/bn/beta', 'conv2_1/1/conv2_1/1/bn/beta/read', 'conv2_1/1/conv2_1/1/bn/moving_mean', 'conv2_1/1/conv2_1/1/bn/moving_mean/read', 'conv2_1/1/conv2_1/1/bn/moving_variance', 'conv2_1/1/conv2_1/1/bn/moving_variance/read', 'conv2_1/1/conv2_1/1/bn/FusedBatchNorm', 'conv2_1/1/Elu', 'Dropout/Identity', 'conv2_1/2/weights', 'conv2_1/2/weights/read', 'conv2_1/2/biases', 'conv2_1/2/biases/read', 'conv2_1/2/Conv2D', 'conv2_1/2/BiasAdd', 'add', 'conv2_3/bn/Const', 'conv2_3/bn/beta', 'conv2_3/bn/beta/read', 'conv2_3/bn/moving_mean', 'conv2_3/bn/moving_mean/read', 'conv2_3/bn/moving_variance', 'conv2_3/bn/moving_variance/read', 'conv2_3/bn/FusedBatchNorm', 'Elu', 'conv2_3/1/weights', 'conv2_3/1/weights/read', 'conv2_3/1/Conv2D', 'conv2_3/1/conv2_3/1/bn/Const', 'conv2_3/1/conv2_3/1/bn/beta', 'conv2_3/1/conv2_3/1/bn/beta/read', 'conv2_3/1/conv2_3/1/bn/moving_mean', 'conv2_3/1/conv2_3/1/bn/moving_mean/read', 'conv2_3/1/conv2_3/1/bn/moving_variance', 'conv2_3/1/conv2_3/1/bn/moving_variance/read', 'conv2_3/1/conv2_3/1/bn/FusedBatchNorm', 'conv2_3/1/Elu', 'Dropout_1/Identity', 'conv2_3/2/weights', 'conv2_3/2/weights/read', 'conv2_3/2/biases', 'conv2_3/2/biases/read', 'conv2_3/2/Conv2D', 'conv2_3/2/BiasAdd', 'add_1', 'conv3_1/bn/Const', 'conv3_1/bn/beta', 'conv3_1/bn/beta/read', 'conv3_1/bn/moving_mean', 'conv3_1/bn/moving_mean/read', 'conv3_1/bn/moving_variance', 'conv3_1/bn/moving_variance/read', 'conv3_1/bn/FusedBatchNorm', 'Elu_1', 'conv3_1/1/weights', 'conv3_1/1/weights/read', 'conv3_1/1/Conv2D', 'conv3_1/1/conv3_1/1/bn/Const', 'conv3_1/1/conv3_1/1/bn/beta', 'conv3_1/1/conv3_1/1/bn/beta/read', 'conv3_1/1/conv3_1/1/bn/moving_mean', 'conv3_1/1/conv3_1/1/bn/moving_mean/read', 'conv3_1/1/conv3_1/1/bn/moving_variance', 'conv3_1/1/conv3_1/1/bn/moving_variance/read', 'conv3_1/1/conv3_1/1/bn/FusedBatchNorm', 'conv3_1/1/Elu', 'Dropout_2/Identity', 'conv3_1/2/weights', 'conv3_1/2/weights/read', 'conv3_1/2/biases', 'conv3_1/2/biases/read', 'conv3_1/2/Conv2D', 'conv3_1/2/BiasAdd', 'conv3_1/projection/weights', 'conv3_1/projection/weights/read', 'conv3_1/projection/Conv2D', 'add_2', 'conv3_3/bn/Const', 'conv3_3/bn/beta', 'conv3_3/bn/beta/read', 'conv3_3/bn/moving_mean', 'conv3_3/bn/moving_mean/read', 'conv3_3/bn/moving_variance', 'conv3_3/bn/moving_variance/read', 'conv3_3/bn/FusedBatchNorm', 'Elu_2', 'conv3_3/1/weights', 'conv3_3/1/weights/read', 'conv3_3/1/Conv2D', 'conv3_3/1/conv3_3/1/bn/Const', 'conv3_3/1/conv3_3/1/bn/beta', 'conv3_3/1/conv3_3/1/bn/beta/read', 'conv3_3/1/conv3_3/1/bn/moving_mean', 'conv3_3/1/conv3_3/1/bn/moving_mean/read', 'conv3_3/1/conv3_3/1/bn/moving_variance', 'conv3_3/1/conv3_3/1/bn/moving_variance/read', 'conv3_3/1/conv3_3/1/bn/FusedBatchNorm', 'conv3_3/1/Elu', 'Dropout_3/Identity', 'conv3_3/2/weights', 'conv3_3/2/weights/read', 'conv3_3/2/biases', 'conv3_3/2/biases/read', 'conv3_3/2/Conv2D', 'conv3_3/2/BiasAdd', 'add_3', 'conv4_1/bn/Const', 'conv4_1/bn/beta', 'conv4_1/bn/beta/read', 'conv4_1/bn/moving_mean', 'conv4_1/bn/moving_mean/read', 'conv4_1/bn/moving_variance', 'conv4_1/bn/moving_variance/read', 'conv4_1/bn/FusedBatchNorm', 'Elu_3', 'conv4_1/1/weights', 'conv4_1/1/weights/read', 'conv4_1/1/Conv2D', 'conv4_1/1/conv4_1/1/bn/Const', 'conv4_1/1/conv4_1/1/bn/beta', 'conv4_1/1/conv4_1/1/bn/beta/read', 'conv4_1/1/conv4_1/1/bn/moving_mean', 'conv4_1/1/conv4_1/1/bn/moving_mean/read', 'conv4_1/1/conv4_1/1/bn/moving_variance', 'conv4_1/1/conv4_1/1/bn/moving_variance/read', 'conv4_1/1/conv4_1/1/bn/FusedBatchNorm', 'conv4_1/1/Elu', 'Dropout_4/Identity', 'conv4_1/2/weights', 'conv4_1/2/weights/read', 'conv4_1/2/biases', 'conv4_1/2/biases/read', 'conv4_1/2/Conv2D', 'conv4_1/2/BiasAdd', 'conv4_1/projection/weights', 'conv4_1/projection/weights/read', 'conv4_1/projection/Conv2D', 'add_4', 'conv4_3/bn/Const', 'conv4_3/bn/beta', 'conv4_3/bn/beta/read', 'conv4_3/bn/moving_mean', 'conv4_3/bn/moving_mean/read', 'conv4_3/bn/moving_variance', 'conv4_3/bn/moving_variance/read', 'conv4_3/bn/FusedBatchNorm', 'Elu_4', 'conv4_3/1/weights', 'conv4_3/1/weights/read', 'conv4_3/1/Conv2D', 'conv4_3/1/conv4_3/1/bn/Const', 'conv4_3/1/conv4_3/1/bn/beta', 'conv4_3/1/conv4_3/1/bn/beta/read', 'conv4_3/1/conv4_3/1/bn/moving_mean', 'conv4_3/1/conv4_3/1/bn/moving_mean/read', 'conv4_3/1/conv4_3/1/bn/moving_variance', 'conv4_3/1/conv4_3/1/bn/moving_variance/read', 'conv4_3/1/conv4_3/1/bn/FusedBatchNorm', 'conv4_3/1/Elu', 'Dropout_5/Identity', 'conv4_3/2/weights', 'conv4_3/2/weights/read', 'conv4_3/2/biases', 'conv4_3/2/biases/read', 'conv4_3/2/Conv2D', 'conv4_3/2/BiasAdd', 'add_5', 'Flatten/flatten/Shape', 'Flatten/flatten/strided_slice/stack', 'Flatten/flatten/strided_slice/stack_1', 'Flatten/flatten/strided_slice/stack_2', 'Flatten/flatten/strided_slice', 'Flatten/flatten/Reshape/shape/1', 'Flatten/flatten/Reshape/shape', 'Flatten/flatten/Reshape', 'Dropout_6/Identity', 'fc1/weights', 'fc1/weights/read', 'fc1/MatMul', 'fc1/fc1/bn/Reshape/shape', 'fc1/fc1/bn/Reshape', 'fc1/fc1/bn/beta', 'fc1/fc1/bn/beta/read', 'fc1/fc1/bn/Const', 'fc1/fc1/bn/moving_mean', 'fc1/fc1/bn/moving_mean/read', 'fc1/fc1/bn/moving_variance', 'fc1/fc1/bn/moving_variance/read', 'fc1/fc1/bn/FusedBatchNorm', 'fc1/fc1/bn/Shape', 'fc1/fc1/bn/Reshape_1', 'fc1/Elu', 'ball/Reshape/shape', 'ball/Reshape', 'ball/beta', 'ball/beta/read', 'ball/Const', 'ball/moving_mean', 'ball/moving_mean/read', 'ball/moving_variance', 'ball/moving_variance/read', 'ball/FusedBatchNorm', 'ball/Shape', 'ball/Reshape_1', 'Const', 'Square', 'Sum/reduction_indices', 'Sum', 'add_6', 'Sqrt', 'truediv', 'features']\n"
     ]
    }
   ],
   "source": [
    "encoder_model_filename = 'model_data/mars-small128.pb'\n",
    "encoder = create_box_encoder(encoder_model_filename, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
